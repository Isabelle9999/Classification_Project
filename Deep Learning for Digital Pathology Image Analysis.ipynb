{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN3W0iDK13FuTvJE4dONjnl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yW1otkz6jpO7","executionInfo":{"status":"ok","timestamp":1736743084040,"user_tz":-480,"elapsed":3687,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}},"outputId":"3deb0b11-d558-43ea-94ee-256e0a3215ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["PROJECT_PATH = '/content/drive/MyDrive/classification_project'"],"metadata":{"id":"QiHmW6fbjvV3","executionInfo":{"status":"ok","timestamp":1736743084040,"user_tz":-480,"elapsed":12,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","import os\n","print(\"Files:\", os.listdir(f\"{PROJECT_PATH}/1-100GEOJSON\"))\n","import pandas as pd\n","import geopandas as gpd\n","import json\n","\n","\n","all_files = os.listdir(f\"{PROJECT_PATH}/1-100GEOJSON\")\n","classification_stats = pd.DataFrame()\n","\n","# Load one file to see structure\n","test_file = [f for f in all_files if f.endswith('.geojson')][0]\n","gdf = gpd.read_file(f\"{PROJECT_PATH}/1-100GEOJSON/{test_file}\")\n","print(\"\\nSample file structure:\")\n","print(gdf.columns)\n","print(\"\\nClassification types:\")\n","print(gdf['classification'].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W3uJsvhTjwZ0","executionInfo":{"status":"ok","timestamp":1736743084040,"user_tz":-480,"elapsed":11,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}},"outputId":"7b3a27cd-cf6a-4af6-911a-1167fc28ae53"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Files: ['TCGA-AC-A3BB-01Z-00-DX1.CE889249-2A5E-44DA-B04E-746BE82CD805.geojson', 'TCGA-A7-A0CG-01Z-00-DX1.D77019C2-96B1-4EF5-A61E-5F2D5B8D9852.geojson', 'TCGA-AO-A0J5-01Z-00-DX1.20C14D0C-1A74-4FE9-A5E6-BDDCB8DE7714.geojson', 'TCGA-E9-A1N4-01Z-00-DX1.71c8d4a5-ec99-4012-9fe2-ddb3349ad5bc.geojson', 'TCGA-E9-A1NC-01Z-00-DX1.20edf036-8ba6-4187-a74c-124fc39f5aa1.geojson', 'TCGA-JL-A3YW-01Z-00-DX1.827C5C53-9C30-4307-802A-5A7896828A7F.geojson', 'TCGA-C8-A137-01Z-00-DX1.87F3775D-A401-4D5E-843F-8FB1D4BE97F8.geojson', 'TCGA-PL-A8LY-01A-02-DX2.6F9520F1-3210-4A96-81C2-A14424F650D1.geojson', 'TCGA-AO-A124-01Z-00-DX1.E3C7B017-6154-4630-9BDE-0CAC946D0209.geojson', 'TCGA-AO-A03U-01Z-00-DX1.AE2B55F3-8BA1-4546-82B7-4D2292BE1C78.geojson', 'TCGA-BH-A0H9-01Z-00-DX1.8AE869C6-5C78-4D52-AC8B-5B6FD5FD91AA.geojson', 'TCGA-A7-A4SF-01Z-00-DX1.CDCFD4BC-4363-4CF2-95F5-4922E04C3B9D.geojson', 'TCGA-AR-A24H-01Z-00-DX1.5CFC7E16-3F38-4531-968C-A4E4C9D00659.geojson', 'TCGA-C8-A1HI-01Z-00-DX1.C6D0F8B8-55ED-477F-BAF7-AA05D0449CC8.geojson', 'TCGA-E9-A247-01Z-00-DX1.3B2DF1CB-054A-44C4-9AD5-D8FA6D386A93.geojson', 'TCGA-AN-A0FZ-01Z-00-DX1.9555AF11-3A0D-4FE3-AE91-09DA77B175CA.geojson', 'TCGA-A8-A06X-01Z-00-DX1.21F19EDD-ABCB-4398-B210-D795BB7A34E3.geojson', 'TCGA-A2-A3XW-01Z-00-DX1.45F5F36F-5503-4A38-AF37-E526915A8DBE.geojson', 'TCGA-BH-A18G-01Z-00-DX1.DB2B5819-CE83-4E07-BD03-2CD9CF2E246C.geojson', 'TCGA-AR-A24O-01Z-00-DX1.04EFBAC8-7A4A-4005-890C-5CC3E1C67DBD.geojson', 'TCGA-E9-A22A-01Z-00-DX1.d986c9eb-2c54-4663-a54b-04c0756db6db.geojson', 'TCGA-AN-A046-01Z-00-DX1.C529B94F-AFE3-4701-BC98-5D6EDF7B82C0.geojson', 'TCGA-BH-A1F6-01Z-00-DX1.E83F0DC0-EA2C-4641-81B0-8702B9C5D579.geojson', 'TCGA-BH-A1F0-01Z-00-DX1.E1557A67-230A-4337-AEC8-158258A917FF.geojson', 'TCGA-AN-A0FY-01Z-00-DX1.25F5E2A1-F92C-4FE1-BD90-0CDDE50DC066.geojson', 'TCGA-EW-A1J2-01Z-00-DX1.F1D8E593-2DF4-44C3-873D-FD3C910011E4.geojson', 'TCGA-A8-A0AB-01Z-00-DX1.103ED338-A0F9-403B-A10C-49840BD60EB8.geojson', 'TCGA-GM-A3XG-01Z-00-DX1.68FFB600-8573-451F-8100-D11DB091F457.geojson', 'TCGA-C8-A138-01Z-00-DX1.845A0680-23A4-4A58-A9C4-2EE17BDBD371.geojson', 'TCGA-AO-A12A-01Z-00-DX1.4E9609A7-9AAD-40A8-8344-8369DF998006.geojson', 'TCGA-AC-A2FB-01Z-00-DX1.A4D93E32-BBD7-45E4-8ACF-3724B059ECBC.geojson', 'TCGA-AN-A0XP-01Z-00-DX1.A4EE3970-5C1F-482E-9AED-F1E3C52A776F.geojson', 'TCGA-A7-A26J-01Z-00-DX1.86A92FBD-F346-4206-A1BE-0CBA1596135F.geojson', 'TCGA-AO-A0J9-01Z-00-DX1.E37C342B-9B6A-4BEE-B064-A82C3579CC66.geojson', 'TCGA-E2-A1L7-01Z-00-DX1.BE796CD2-2E81-44E8-8CA2-85B4D2A31B64.geojson', 'TCGA-A1-A0SJ-01Z-00-DX1.C196FA66-C376-4016-86BC-3D8E745B3A51.geojson', 'TCGA-A2-A0CQ-01Z-00-DX1.4E5FB4E5-A08C-4C87-A3BE-0640A95AE649.geojson', 'TCGA-BH-A1EY-01Z-00-DX1.25C3DE1F-C702-4959-8DFA-69EF78AD9307.geojson', 'TCGA-B6-A0RN-01Z-00-DX1.0D02A3FB-D694-4A5B-80C1-CF1469E29BFD.geojson', 'TCGA-AO-A0JB-01Z-00-DX1.250FE098-345B-4981-9236-0519E1C9058E.geojson', 'TCGA-C8-A12Q-01Z-00-DX1.CE74E5B7-FD30-4CBE-8716-ECCF2213AAC3.geojson', 'TCGA-A7-A0CG-01Z-00-DX2.81138E90-373A-4C12-B9CA-6EEF5F84A5B5.geojson', 'TCGA-E2-A1IN-01Z-00-DX1.F63F004F-847D-41B0-BAEF-3189D4965838.geojson', 'TCGA-BH-A0BS-01Z-00-DX1.FEE32127-4D0B-4560-A39C-4EAA5B189B70.geojson', 'TCGA-A8-A07G-01Z-00-DX1.37E8A762-8141-4BE6-935A-B3DCB712BB4A.geojson', 'TCGA-AN-A0XU-01Z-00-DX1.6B0DD0FF-A20D-4BA2-8D48-FC357BA5313F.geojson', 'TCGA-AN-A0FL-01Z-00-DX1.20A041C6-A306-4599-A7D1-65032A252AA9.geojson', 'TCGA-A7-A6VV-01Z-00-DX2.4C2BF8C1-CC84-4A6E-BC0F-430BC8BE6B26.geojson', 'TCGA-A8-A07R-01Z-00-DX1.D716752E-86AF-468B-A905-A7894B978F22.geojson', 'TCGA-A7-A3RF-01Z-00-DX1.E60647BC-229D-4409-A564-EE0945F912EE.geojson', 'TCGA-C8-A278-01Z-00-DX1.188B3FE0-7B20-401A-A6B7-8F1798018162.geojson', 'TCGA-A8-A07J-01Z-00-DX1.FE16248C-D890-4750-A9FC-5F72BE8D8B85.geojson', 'TCGA-A2-A04Y-01Z-00-DX1.4DC97AD6-4806-4A3A-A998-FD36F93590A4.geojson', 'TCGA-A8-A07Z-01Z-00-DX1.713945D9-6855-456D-87FB-EF8AF8980F51.geojson', 'TCGA-4H-AAAK-01Z-00-DX1.ABF1B042-1970-4E28-8671-43AAD393D2F9.geojson', 'TCGA-AO-A12H-01Z-00-DX1.C6CCBD9D-FB41-4F6C-84FB-A43E0A77E696.geojson', 'TCGA-AR-A1AY-01Z-00-DX1.6AC0BE3B-FFC5-4EDA-9E40-B18CAAC52B81.geojson', 'TCGA-A2-A0EW-01Z-00-DX1.F24495CB-63D8-483F-9834-F761E3F16BF0.geojson', 'TCGA-BH-A0BT-01Z-00-DX1.9087B9E7-C0CD-4179-AF57-AD9255785169.geojson', 'TCGA-A2-A04P-01Z-00-DX1.5B481E02-D269-4732-8FDD-6494E6EE2B71.geojson', 'TCGA-AO-A0JM-01Z-00-DX1.94E75EFD-E5F5-4DF8-93A0-ED94CB4D203A.geojson', 'TCGA-BH-A42V-01Z-00-DX1.B6D78256-05D1-45FA-826A-1B8554D60B7D.geojson', 'TCGA-E9-A22E-01Z-00-DX1.3d5b1ba6-466f-4852-b1fc-bc29ef3be9a2.geojson', 'TCGA-E2-A1IK-01Z-00-DX1.25C554BB-AA90-4FF4-9D68-EEC899B8A27D.geojson', 'TCGA-D8-A1JI-01Z-00-DX2.E688E270-26C9-43EC-BC26-86BF8B74A31D.geojson', 'TCGA-C8-A26Y-01Z-00-DX1.166EE604-4EF3-401D-99E9-3A9711316CC4.geojson', 'TCGA-AC-A5XU-01Z-00-DX1.1AEEFAAF-0906-4086-8022-13B689FAB9F5.geojson', 'TCGA-AN-A0G0-01Z-00-DX1.BE0BB5DF-DEDA-48D8-B5D8-2735C767F28F.geojson', 'TCGA-B6-A0WS-01Z-00-DX1.020ED7BF-9497-4F13-AA07-FE0E839F9A06.geojson', 'TCGA-BH-A1FH-01Z-00-DX1.F90A691F-B6DB-4C4A-9975-9A2CB01F29E2.geojson', 'TCGA-E2-A10F-01Z-00-DX1.18F9324C-A38F-478E-95DF-B8E172D0DD07.geojson', 'TCGA-AR-A251-01Z-00-DX1.E91E357A-3AD4-4F79-A698-05F0B21A37EC.geojson', 'TCGA-C8-A8HR-01Z-00-DX1.8E841CA8-1CE2-4242-AC5A-3247075CF8F4.geojson', 'TCGA-GM-A3NY-01Z-00-DX1.BEED8B8F-5A1B-4CE2-BB5D-A7ED40551AE4.geojson', 'TCGA-D8-A1JI-01Z-00-DX1.9BDB647F-EEAB-4235-BE44-A3815A48CCE0.geojson', 'TCGA-D8-A141-01Z-00-DX2.DBD0D81E-28FC-4466-BDE3-94753BD6CBEB.geojson', 'TCGA-A7-A0D9-01Z-00-DX2.66CD9ED8-223B-4AC8-AA1A-2481FB0C47B3.geojson', 'TCGA-BH-A0EA-01Z-00-DX1.85FF2B48-2AF7-4C15-A7E6-FCA68CAB76C7.geojson', 'TCGA-A7-A3IZ-01Z-00-DX1.7437130B-DF49-40C8-ABCD-FF9364B9B1B0.geojson', 'TCGA-AN-A0FJ-01Z-00-DX1.97B60767-916E-4938-9D0B-E6C0FE1CB3FC.geojson', 'TCGA-AC-A3YI-01Z-00-DX1.321C0A32-ABF9-48ED-8071-C6B1774E9F7B.geojson', 'TCGA-AN-A0AS-01Z-00-DX1.51E551E9-E5F4-4C94-9B25-71DA41109E92.geojson', 'TCGA-MS-A51U-01Z-00-DX1.490DE85A-ECE5-4E2A-9657-841BE6FFCCA0.geojson', 'TCGA-A8-A07P-01Z-00-DX1.2C7C75EF-EEE2-4A42-994C-A1A40850C87A.geojson', 'TCGA-AR-A1AW-01Z-00-DX1.E527CA46-D83F-4055-8C7E-AEFEF13C1E29.geojson', 'TCGA-GI-A2C9-01Z-00-DX1.90181423-51ED-41FE-9B8F-973A67793D4F.geojson', 'TCGA-AC-A3QP-01Z-00-DX1.4B97E53E-1069-40C5-A062-C988663B37DD.geojson', 'TCGA-E2-A153-01Z-00-DX1.CA994467-E541-4131-A9FC-DCD9944F29C4.geojson', 'TCGA-D8-A1JT-01Z-00-DX2.8DB9BB5B-17F3-4D80-835D-872BA275FD3B.geojson', 'TCGA-LD-A7W6-01Z-00-DX1.3E125146-B447-4973-AE09-6D374970B46C.geojson', 'TCGA-A8-A092-01Z-00-DX1.2A55EA0C-47CD-426B-9697-F2B761730585.geojson', 'TCGA-BH-A0B8-01Z-00-DX1.380ABAE9-EA83-4E9B-BFB2-6476A86C1ADD.geojson', 'TCGA-AC-A2QJ-01Z-00-DX1.48C303BB-5A23-4037-BD28-77629A8CD9DA.geojson', 'TCGA-BH-A18S-01Z-00-DX1.B36FC684-0010-4ABB-9E25-303C8DF1C4E2.geojson', 'TCGA-A7-A0CJ-01Z-00-DX2.4B591117-5FC9-4B43-8A45-444CCCABC666.geojson', 'TCGA-D8-A27N-01Z-00-DX1.85613A4F-1FFB-4091-B925-8E8A7C7A6D95.geojson', 'TCGA-OL-A66O-01Z-00-DX1.5F1E4C60-5CE8-41B4-A94D-4AA80D9253F9.geojson', 'TCGA-A1-A0SI-01Z-00-DX1.AB717348-F964-4F29-BBE2-972B7C640432.geojson', 'TCGA-A8-A075-01Z-00-DX1.8E06AF51-951F-48E8-934E-42A455F65E5F.geojson', 'TCGA-PL-A8LY-01A-01-DX1.32047D5E-8A42-480A-B2B8-A56B47B949FD.geojson', 'TCGA-BH-A0BS-01Z-00-DX1.FEE32127-4D0B-4560-A39C-4EAA5B189B70.csv', 'TCGA-AO-A0J5-01Z-00-DX1.20C14D0C-1A74-4FE9-A5E6-BDDCB8DE7714.csv', 'TCGA-AO-A0JM-01Z-00-DX1.94E75EFD-E5F5-4DF8-93A0-ED94CB4D203A.csv', 'TCGA-D8-A1JT-01Z-00-DX2.8DB9BB5B-17F3-4D80-835D-872BA275FD3B.csv', 'TCGA-AO-A0JB-01Z-00-DX1.250FE098-345B-4981-9236-0519E1C9058E.csv', 'TCGA-A8-A092-01Z-00-DX1.2A55EA0C-47CD-426B-9697-F2B761730585.csv', 'TCGA-AC-A3BB-01Z-00-DX1.CE889249-2A5E-44DA-B04E-746BE82CD805.csv', 'TCGA-4H-AAAK-01Z-00-DX1.ABF1B042-1970-4E28-8671-43AAD393D2F9.csv', 'TCGA-BH-A0H9-01Z-00-DX1.8AE869C6-5C78-4D52-AC8B-5B6FD5FD91AA.csv', 'TCGA-E9-A1N4-01Z-00-DX1.71c8d4a5-ec99-4012-9fe2-ddb3349ad5bc.csv', 'TCGA-AO-A12H-01Z-00-DX1.C6CCBD9D-FB41-4F6C-84FB-A43E0A77E696.csv', 'TCGA-BH-A42V-01Z-00-DX1.B6D78256-05D1-45FA-826A-1B8554D60B7D.csv', 'TCGA-BH-A18G-01Z-00-DX1.DB2B5819-CE83-4E07-BD03-2CD9CF2E246C.csv', 'TCGA-A1-A0SJ-01Z-00-DX1.C196FA66-C376-4016-86BC-3D8E745B3A51.csv', 'TCGA-D8-A141-01Z-00-DX2.DBD0D81E-28FC-4466-BDE3-94753BD6CBEB.csv', 'TCGA-BH-A0EA-01Z-00-DX1.85FF2B48-2AF7-4C15-A7E6-FCA68CAB76C7.csv', 'TCGA-BH-A1EY-01Z-00-DX1.25C3DE1F-C702-4959-8DFA-69EF78AD9307.csv', 'TCGA-AN-A0XP-01Z-00-DX1.A4EE3970-5C1F-482E-9AED-F1E3C52A776F.csv', 'TCGA-C8-A138-01Z-00-DX1.845A0680-23A4-4A58-A9C4-2EE17BDBD371.csv', 'TCGA-A2-A04Y-01Z-00-DX1.4DC97AD6-4806-4A3A-A998-FD36F93590A4.csv', 'TCGA-AO-A124-01Z-00-DX1.E3C7B017-6154-4630-9BDE-0CAC946D0209.csv', 'TCGA-AR-A24H-01Z-00-DX1.5CFC7E16-3F38-4531-968C-A4E4C9D00659.csv', 'TCGA-E2-A1L7-01Z-00-DX1.BE796CD2-2E81-44E8-8CA2-85B4D2A31B64.csv', 'TCGA-AN-A0FY-01Z-00-DX1.25F5E2A1-F92C-4FE1-BD90-0CDDE50DC066.csv', 'TCGA-AR-A251-01Z-00-DX1.E91E357A-3AD4-4F79-A698-05F0B21A37EC.csv', 'TCGA-A2-A3XW-01Z-00-DX1.45F5F36F-5503-4A38-AF37-E526915A8DBE.csv', 'TCGA-C8-A12Q-01Z-00-DX1.CE74E5B7-FD30-4CBE-8716-ECCF2213AAC3.csv', 'TCGA-PL-A8LY-01A-02-DX2.6F9520F1-3210-4A96-81C2-A14424F650D1.csv', 'TCGA-A7-A26J-01Z-00-DX1.86A92FBD-F346-4206-A1BE-0CBA1596135F.csv', 'TCGA-C8-A137-01Z-00-DX1.87F3775D-A401-4D5E-843F-8FB1D4BE97F8.csv', 'TCGA-A8-A06X-01Z-00-DX1.21F19EDD-ABCB-4398-B210-D795BB7A34E3.csv', 'TCGA-A8-A07P-01Z-00-DX1.2C7C75EF-EEE2-4A42-994C-A1A40850C87A.csv', 'TCGA-OL-A66O-01Z-00-DX1.5F1E4C60-5CE8-41B4-A94D-4AA80D9253F9.csv', 'TCGA-AC-A2QJ-01Z-00-DX1.48C303BB-5A23-4037-BD28-77629A8CD9DA.csv', 'TCGA-A7-A0D9-01Z-00-DX2.66CD9ED8-223B-4AC8-AA1A-2481FB0C47B3.csv', 'TCGA-AN-A0G0-01Z-00-DX1.BE0BB5DF-DEDA-48D8-B5D8-2735C767F28F.csv', 'TCGA-E9-A1NC-01Z-00-DX1.20edf036-8ba6-4187-a74c-124fc39f5aa1.csv', 'TCGA-E9-A22A-01Z-00-DX1.d986c9eb-2c54-4663-a54b-04c0756db6db.csv', 'TCGA-AN-A046-01Z-00-DX1.C529B94F-AFE3-4701-BC98-5D6EDF7B82C0.csv', 'TCGA-AN-A0XU-01Z-00-DX1.6B0DD0FF-A20D-4BA2-8D48-FC357BA5313F.csv', 'TCGA-BH-A1F0-01Z-00-DX1.E1557A67-230A-4337-AEC8-158258A917FF.csv', 'TCGA-BH-A0BT-01Z-00-DX1.9087B9E7-C0CD-4179-AF57-AD9255785169.csv', 'TCGA-A1-A0SI-01Z-00-DX1.AB717348-F964-4F29-BBE2-972B7C640432.csv', 'TCGA-C8-A26Y-01Z-00-DX1.166EE604-4EF3-401D-99E9-3A9711316CC4.csv', 'TCGA-A8-A07Z-01Z-00-DX1.713945D9-6855-456D-87FB-EF8AF8980F51.csv', 'TCGA-A8-A0AB-01Z-00-DX1.103ED338-A0F9-403B-A10C-49840BD60EB8.csv', 'TCGA-BH-A0B8-01Z-00-DX1.380ABAE9-EA83-4E9B-BFB2-6476A86C1ADD.csv', 'TCGA-A7-A3IZ-01Z-00-DX1.7437130B-DF49-40C8-ABCD-FF9364B9B1B0.csv', 'TCGA-AN-A0FJ-01Z-00-DX1.97B60767-916E-4938-9D0B-E6C0FE1CB3FC.csv', 'TCGA-BH-A1F6-01Z-00-DX1.E83F0DC0-EA2C-4641-81B0-8702B9C5D579.csv', 'TCGA-E9-A22E-01Z-00-DX1.3d5b1ba6-466f-4852-b1fc-bc29ef3be9a2.csv', 'TCGA-AN-A0FZ-01Z-00-DX1.9555AF11-3A0D-4FE3-AE91-09DA77B175CA.csv', 'TCGA-D8-A1JI-01Z-00-DX2.E688E270-26C9-43EC-BC26-86BF8B74A31D.csv', 'TCGA-A8-A075-01Z-00-DX1.8E06AF51-951F-48E8-934E-42A455F65E5F.csv', 'TCGA-C8-A8HR-01Z-00-DX1.8E841CA8-1CE2-4242-AC5A-3247075CF8F4.csv', 'TCGA-C8-A278-01Z-00-DX1.188B3FE0-7B20-401A-A6B7-8F1798018162.csv', 'TCGA-A2-A0EW-01Z-00-DX1.F24495CB-63D8-483F-9834-F761E3F16BF0.csv', 'TCGA-A8-A07J-01Z-00-DX1.FE16248C-D890-4750-A9FC-5F72BE8D8B85.csv', 'TCGA-A7-A3RF-01Z-00-DX1.E60647BC-229D-4409-A564-EE0945F912EE.csv', 'TCGA-JL-A3YW-01Z-00-DX1.827C5C53-9C30-4307-802A-5A7896828A7F.csv', 'TCGA-PL-A8LY-01A-01-DX1.32047D5E-8A42-480A-B2B8-A56B47B949FD.csv', 'TCGA-A8-A07G-01Z-00-DX1.37E8A762-8141-4BE6-935A-B3DCB712BB4A.csv', 'TCGA-AC-A2FB-01Z-00-DX1.A4D93E32-BBD7-45E4-8ACF-3724B059ECBC.csv', 'TCGA-E9-A247-01Z-00-DX1.3B2DF1CB-054A-44C4-9AD5-D8FA6D386A93.csv', 'TCGA-LD-A7W6-01Z-00-DX1.3E125146-B447-4973-AE09-6D374970B46C.csv', 'TCGA-AR-A1AW-01Z-00-DX1.E527CA46-D83F-4055-8C7E-AEFEF13C1E29.csv', 'TCGA-A8-A07R-01Z-00-DX1.D716752E-86AF-468B-A905-A7894B978F22.csv', 'TCGA-E2-A1IN-01Z-00-DX1.F63F004F-847D-41B0-BAEF-3189D4965838.csv', 'TCGA-A7-A0CG-01Z-00-DX1.D77019C2-96B1-4EF5-A61E-5F2D5B8D9852.csv', 'TCGA-AO-A12A-01Z-00-DX1.4E9609A7-9AAD-40A8-8344-8369DF998006.csv', 'TCGA-AN-A0AS-01Z-00-DX1.51E551E9-E5F4-4C94-9B25-71DA41109E92.csv', 'TCGA-AO-A0J9-01Z-00-DX1.E37C342B-9B6A-4BEE-B064-A82C3579CC66.csv', 'TCGA-B6-A0WS-01Z-00-DX1.020ED7BF-9497-4F13-AA07-FE0E839F9A06.csv', 'TCGA-AR-A24O-01Z-00-DX1.04EFBAC8-7A4A-4005-890C-5CC3E1C67DBD.csv', 'TCGA-MS-A51U-01Z-00-DX1.490DE85A-ECE5-4E2A-9657-841BE6FFCCA0.csv', 'TCGA-A7-A0CJ-01Z-00-DX2.4B591117-5FC9-4B43-8A45-444CCCABC666.csv', 'TCGA-AC-A3YI-01Z-00-DX1.321C0A32-ABF9-48ED-8071-C6B1774E9F7B.csv', 'TCGA-GM-A3NY-01Z-00-DX1.BEED8B8F-5A1B-4CE2-BB5D-A7ED40551AE4.csv', 'TCGA-AO-A03U-01Z-00-DX1.AE2B55F3-8BA1-4546-82B7-4D2292BE1C78.csv', 'TCGA-A2-A0CQ-01Z-00-DX1.4E5FB4E5-A08C-4C87-A3BE-0640A95AE649.csv', 'TCGA-A7-A0CG-01Z-00-DX2.81138E90-373A-4C12-B9CA-6EEF5F84A5B5.csv', 'TCGA-AN-A0FL-01Z-00-DX1.20A041C6-A306-4599-A7D1-65032A252AA9.csv', 'TCGA-GI-A2C9-01Z-00-DX1.90181423-51ED-41FE-9B8F-973A67793D4F.csv', 'TCGA-GM-A3XG-01Z-00-DX1.68FFB600-8573-451F-8100-D11DB091F457.csv', 'TCGA-BH-A18S-01Z-00-DX1.B36FC684-0010-4ABB-9E25-303C8DF1C4E2.csv', 'TCGA-C8-A1HI-01Z-00-DX1.C6D0F8B8-55ED-477F-BAF7-AA05D0449CC8.csv', 'TCGA-AC-A3QP-01Z-00-DX1.4B97E53E-1069-40C5-A062-C988663B37DD.csv', 'TCGA-A7-A4SF-01Z-00-DX1.CDCFD4BC-4363-4CF2-95F5-4922E04C3B9D.csv', 'TCGA-B6-A0RN-01Z-00-DX1.0D02A3FB-D694-4A5B-80C1-CF1469E29BFD.csv', 'TCGA-E2-A1IK-01Z-00-DX1.25C554BB-AA90-4FF4-9D68-EEC899B8A27D.csv', 'TCGA-E2-A153-01Z-00-DX1.CA994467-E541-4131-A9FC-DCD9944F29C4.csv', 'TCGA-AR-A1AY-01Z-00-DX1.6AC0BE3B-FFC5-4EDA-9E40-B18CAAC52B81.csv', 'TCGA-A7-A6VV-01Z-00-DX2.4C2BF8C1-CC84-4A6E-BC0F-430BC8BE6B26.csv', 'TCGA-A2-A04P-01Z-00-DX1.5B481E02-D269-4732-8FDD-6494E6EE2B71.csv', 'TCGA-EW-A1J2-01Z-00-DX1.F1D8E593-2DF4-44C3-873D-FD3C910011E4.csv', 'TCGA-D8-A27N-01Z-00-DX1.85613A4F-1FFB-4091-B925-8E8A7C7A6D95.csv', 'TCGA-E2-A10F-01Z-00-DX1.18F9324C-A38F-478E-95DF-B8E172D0DD07.csv']\n","\n","Sample file structure:\n","Index(['id', 'objectType', 'classification', 'geometry'], dtype='object')\n","\n","Classification types:\n","0    { \"name\": \"vasculature\", \"color\": [ 213, 40, 1...\n","Name: classification, dtype: object\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import geopandas as gpd\n","import json\n","\n","geojson_files = [f for f in os.listdir(f\"{PROJECT_PATH}/1-100GEOJSON\") if f.endswith('.geojson')]\n","\n","def process_geojson(file_path):\n","    gdf = gpd.read_file(file_path)\n","\n","    gdf['classification'] = gdf['classification'].apply(\n","        lambda x: json.loads(x) if isinstance(x, str) else x\n","    )\n","    gdf['class_name'] = gdf['classification'].apply(\n","        lambda x: x['name'] if isinstance(x, dict) and 'name' in x else None\n","    )\n","    return gdf\n","\n","sample_file = geojson_files[0]\n","sample_gdf = process_geojson(f\"{PROJECT_PATH}/1-100GEOJSON/{sample_file}\")\n","print(\"\\nSample data structure:\")\n","print(sample_gdf[['id', 'objectType', 'class_name']].head())\n","\n","\n","all_classes = []\n","for file in geojson_files:\n","    gdf = process_geojson(f\"{PROJECT_PATH}/1-100GEOJSON/{file}\")\n","    all_classes.extend(gdf['class_name'].tolist())\n","\n","class_distribution = pd.Series(all_classes).value_counts()\n","print(class_distribution)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wKxVA99jwdn","executionInfo":{"status":"ok","timestamp":1736743098231,"user_tz":-480,"elapsed":14201,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}},"outputId":"4d74f153-ef6d-4ec7-c5b8-aec4640a0fcc"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Sample data structure:\n","                                     id  objectType   class_name\n","0  66dec096-daf4-4d19-bac2-6160e7b99d32  annotation  vasculature\n","adipose tissue                 20206\n","vasculature                     1782\n","nomal breast gland              1048\n","invasive cancer                  447\n","Immune cells                     248\n","cancer in situ                   229\n","atypical ductal hyperplasia      229\n","Necrosis                          41\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["# Dictionary to store image-annotation pairs\n","data_pairs = {}\n","for geojson_file in geojson_files:\n","    base_name = geojson_file.replace('.geojson', '')\n","    data_pairs[base_name] = {\n","        'geojson': geojson_file,\n","        'csv': base_name + '.csv'\n","    }\n","\n","print(f\"\\nNumber of image-annotation pairs: {len(data_pairs)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjyO2FSpjwgU","executionInfo":{"status":"ok","timestamp":1736743098231,"user_tz":-480,"elapsed":14,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}},"outputId":"55c00661-c110-4ea0-a425-d1774cb7e2b3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Number of image-annotation pairs: 100\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torch.cuda as cuda\n","import gc\n","from tqdm import tqdm\n","import logging\n","import sys\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from torchvision import transforms\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from torch.utils.data.sampler import WeightedRandomSampler\n","from sklearn.utils.class_weight import compute_class_weight\n","from shapely.geometry import Point\n","import cv2\n","from scipy import stats\n","from skimage import filters\n","from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score\n","from torch.optim.lr_scheduler import OneCycleLR\n"],"metadata":{"id":"tdI6C04ujwjD","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":14,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["logging.basicConfig(\n","    level=logging.INFO,\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    handlers=[\n","        logging.FileHandler('training.log'),\n","        logging.StreamHandler(sys.stdout)\n","    ]\n",")"],"metadata":{"id":"-sRdT-uSMrw2","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":13,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","def setup_training_config():\n","    config = {\n","        # Model parameters\n","        'hidden_dim': 768,\n","        'num_heads': 12,\n","        'num_layers': 12,\n","        'patch_size': 16,\n","\n","        # Training parameters\n","        'batch_size': 32,\n","        'num_epochs': 100,\n","        'learning_rate': 2e-4,\n","        'weight_decay': 0.05,\n","        'warmup_epochs': 10,\n","\n","        # Regularization\n","        'dropout': 0.1,\n","        'label_smoothing': 0.1,\n","\n","        # Optimizer parameters\n","        'optimizer_params': {\n","            'betas': (0.9, 0.999),\n","            'eps': 1e-8\n","        },\n","\n","        # Learning rate scheduler\n","        'scheduler_params': {\n","            'num_warmup_steps': 0,  # Will be calculated based on warmup_epochs\n","            'num_training_steps': 0  # Will be calculated based on dataset size\n","        }\n","    }\n","\n","    return config\n","\n","\n","config = setup_training_config()\n","\n","PATCH_SIZE = config['patch_size']\n","BATCH_SIZE = config['batch_size']\n","num_epochs = config['num_epochs']\n","CHECKPOINT_FREQ = 5\n","LEARNING_RATE = config['learning_rate']\n","\n","def setup_training():\n","    if torch.cuda.is_available():\n","        logging.info(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n","        logging.info(f\"Initial GPU Memory: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n","\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","    else:\n","        logging.warning(\"No GPU available, using CPU\")\n","\n","    checkpoint_dir = os.path.join(PROJECT_PATH, 'checkpoints')\n","    os.makedirs(checkpoint_dir, exist_ok=True)\n","    return checkpoint_dir\n","\n","def save_checkpoint(epoch, model, optimizer, loss, acc, checkpoint_dir):\n","    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pt')\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': loss,\n","        'accuracy': acc\n","    }, checkpoint_path)\n","    logging.info(f\"Saved checkpoint for epoch {epoch}\")\n","\n","class CancerDataset(Dataset):\n","    def __init__(self, geojson_dir, transform=None, phase='train'):\n","        self.geojson_dir = geojson_dir\n","        self.transform = transform\n","        self.phase = phase\n","\n","\n","        self.class_mapping = {\n","            'adipose tissue': 0,\n","            'vasculature': 1,\n","            'nomal breast gland': 2,\n","            'invasive cancer': 3,\n","            'Immune cells': 4,\n","            'atypical ductal hyperplasia': 5,\n","            'cancer in situ': 6,\n","            'Necrosis': 7\n","        }\n","\n","        self.annotations = self._load_annotations()\n","\n","        # Calculate class weights for balanced sampling\n","        self.class_weights = self._calculate_class_weights()\n","\n","        if self.transform is None:\n","            self.transform = transforms.Compose([\n","                transforms.RandomHorizontalFlip(),\n","                transforms.RandomVerticalFlip(),\n","                transforms.RandomRotation(10),\n","                transforms.ColorJitter(brightness=0.2, contrast=0.2),\n","                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                  std=[0.229, 0.224, 0.225])\n","            ])\n","\n","    def _load_annotations(self):\n","        annotations = []\n","        geojson_files = [f for f in os.listdir(self.geojson_dir) if f.endswith('.geojson')]\n","\n","        # Add progress bar\n","        for i, file in enumerate(tqdm(geojson_files, desc='Loading annotations')):\n","            try:\n","                gdf = gpd.read_file(os.path.join(self.geojson_dir, file))\n","                gdf['classification'] = gdf['classification'].apply(\n","                    lambda x: json.loads(x) if isinstance(x, str) else x\n","                )\n","                gdf['class_name'] = gdf['classification'].apply(\n","                    lambda x: x['name'] if isinstance(x, dict) and 'name' in x else None\n","                )\n","\n","                for _, row in gdf.iterrows():\n","                    if row['class_name'] in self.class_mapping:\n","                        annotations.append({\n","                            'file': file,\n","                            'geometry': row['geometry'],\n","                            'class_name': row['class_name'],\n","                            'class': self.class_mapping[row['class_name']]\n","                        })\n","            except Exception as e:\n","                print(f\"Error processing file {file}: {str(e)}\")\n","\n","        return annotations\n","\n","    def calculate_class_weights(dataset):\n","      # Count samples per class\n","      class_counts = {}\n","      for annotation in dataset.annotations:\n","          class_counts[annotation['class']] = class_counts.get(annotation['class'], 0) + 1\n","\n","      # Calculate balanced weights\n","      total_samples = len(dataset.annotations)\n","      num_classes = len(dataset.class_mapping)\n","      weights = {}\n","\n","      for cls, count in class_counts.items():\n","          # Modified weight calculation using effective number of samples\n","          beta = 0.9999\n","          effective_num = 1.0 - np.power(beta, count)\n","          weights[cls] = (1.0 - beta) / effective_num\n","\n","      # Normalize weights\n","      weight_sum = sum(weights.values())\n","      weights = {cls: weight/weight_sum * num_classes for cls, weight in weights.items()}\n","\n","      return weights\n","\n","    def __getitem__(self, idx):\n","        annotation = self.annotations[idx]\n","\n","        features = self._extract_patch_features(annotation['geometry'])\n","        features = torch.FloatTensor(features).permute(2, 0, 1)\n","\n","        # Apply transformations\n","        if self.transform:\n","            features = self.transform(features)\n","\n","        return features, annotation['class']\n","\n","    def _extract_patch_features(self, geometry):\n","        minx, miny, maxx, maxy = geometry.bounds\n","        area = geometry.area\n","        perimeter = geometry.length\n","\n","\n","        compactness = 4 * np.pi * area / (perimeter * perimeter) if perimeter > 0 else 0\n","        elongation = (maxx - minx) / (maxy - miny) if (maxy - miny) > 0 else 1\n","\n","        features = np.zeros((PATCH_SIZE, PATCH_SIZE, 5))\n","\n","\n","\n","        features[:,:,0] = area / (PATCH_SIZE * PATCH_SIZE)\n","        features[:,:,1] = perimeter / (4 * PATCH_SIZE)\n","        features[:,:,2] = compactness\n","        features[:,:,3] = elongation\n","        features[:,:,4] = geometry.area / geometry.convex_hull.area if not geometry.is_empty else 1\n","\n","        return features\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def get_sample_weights(self):\n","        weights = [self.class_weights[annotation['class']] for annotation in self.annotations]\n","        return torch.DoubleTensor(weights)\n"],"metadata":{"id":"lLI362f3jwmk","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":13,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def process_whole_slide(wsi_path):\n","    \"\"\"\n","    \"\"\"\n","\n","    wsi = openslide.OpenSlide(wsi_path)\n","    width = wsi.dimensions[0]\n","    height = wsi.dimensions[1]\n","\n","    tile_size = 512\n","\n","    tiles = []\n","    coords = []\n","\n","    thumbnail = wsi.get_thumbnail((width//32, height//32))\n","    thumbnail_gray = cv2.cvtColor(np.array(thumbnail), cv2.COLOR_RGB2GRAY)\n","    tissue_mask = thumbnail_gray < filters.threshold_otsu(thumbnail_gray)\n","\n","    # Extract tiles\n","    for y in range(0, height, tile_size):\n","        for x in range(0, width, tile_size):\n","            mask_x = x // 32\n","            mask_y = y // 32\n","            if mask_x < tissue_mask.shape[1] and mask_y < tissue_mask.shape[0]:\n","                if tissue_mask[mask_y, mask_x]:\n","                    tile = wsi.read_region((x, y), 0, (tile_size, tile_size))\n","                    tile = tile.convert('RGB')\n","\n","                    # Filter out background tiles\n","                    tile_array = np.array(tile)\n","                    if np.mean(tile_array) < 240:\n","                        tiles.append(tile_array)\n","                        coords.append((x, y))\n","\n","    return np.array(tiles), coords\n"],"metadata":{"id":"IevnYYDMfKpe","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":13,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def pixel_wise_labeling(model, wsi):\n","    \"\"\"\n","    \"\"\"\n","    height, width = wsi.shape[:2]\n","\n","    prediction_mask = np.zeros((height, width), dtype=np.uint8)\n","    window_size = 512\n","    stride = 256\n","\n","    for y in range(0, height - window_size + 1, stride):\n","        for x in range(0, width - window_size + 1, stride):\n","            patch = wsi[y:y+window_size, x:x+window_size]\n","            patch = cv2.resize(patch, (224, 224))\n","            patch = patch / 255.0\n","            patch = np.expand_dims(patch, axis=0)\n","\n","\n","            pred = model.predict(patch)\n","            label = np.argmax(pred[0])\n","\n","            prediction_mask[y:y+window_size, x:x+window_size] = label\n","\n","    return prediction_mask"],"metadata":{"id":"zKyb3xA5fL0-","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":12,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def compare_baseline(our_results, baseline_results):\n","    \"\"\"\n","\n","    \"\"\"\n","    metrics = {\n","        'confusion_matrix': confusion_matrix(baseline_results, our_results),\n","        'classification_report': classification_report(baseline_results, our_results, output_dict=True),\n","        'cohen_kappa': cohen_kappa_score(baseline_results, our_results)\n","    }\n","\n","    class_accuracies = {}\n","    for class_name in set(baseline_results):\n","        class_mask = (baseline_results == class_name)\n","        class_acc = np.mean(our_results[class_mask] == baseline_results[class_mask])\n","        class_accuracies[f'class_{class_name}_accuracy'] = class_acc\n","\n","    metrics['class_accuracies'] = class_accuracies\n","\n","    # Statistical significance\n","    contingency_table = pd.crosstab(pd.Series(baseline_results), pd.Series(our_results))\n","    chi2, p_value = stats.chi2_contingency(contingency_table)[:2]\n","    metrics['statistical_tests'] = {\n","        'chi2': chi2,\n","        'p_value': p_value\n","    }\n","\n","    return metrics"],"metadata":{"id":"UyTb5ZFUfOPp","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":12,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class VisionTransformer(nn.Module):\n","    def __init__(self, num_classes=8, patch_size=16, hidden_dim=768, num_heads=12, num_layers=12):\n","        super().__init__()\n","\n","        # Input normalization\n","        self.input_norm = nn.LayerNorm(5)  # 5 channels from geometric features\n","\n","        # Improved patch embedding\n","        self.patch_embed = nn.Sequential(\n","            nn.Conv2d(5, hidden_dim, kernel_size=patch_size, stride=patch_size),\n","            nn.LayerNorm(hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.1)\n","        )\n","\n","        # Position embedding with learned parameters\n","        self.pos_embed = nn.Parameter(torch.zeros(1, (224 // patch_size) ** 2 + 1, hidden_dim))\n","        self.cls_token = nn.Parameter(torch.zeros(1, 1, hidden_dim))\n","\n","        # Transformer encoder with layer normalization before attention and MLP\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=hidden_dim,\n","            nhead=num_heads,\n","            dim_feedforward=hidden_dim * 4,\n","            dropout=0.1,\n","            activation='gelu',\n","            norm_first=True  # Pre-norm architecture\n","        )\n","        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","\n","        # Classification head with dropout\n","        self.head = nn.Sequential(\n","            nn.LayerNorm(hidden_dim),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_dim, hidden_dim // 2),\n","            nn.GELU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(hidden_dim // 2, num_classes)\n","        )\n","\n","        # Initialize weights\n","        self._init_weights()\n","\n","    def _init_weights(self):\n","        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n","        nn.init.trunc_normal_(self.cls_token, std=0.02)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.trunc_normal_(m.weight, std=0.02)\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.LayerNorm):\n","                nn.init.constant_(m.bias, 0)\n","                nn.init.constant_(m.weight, 1.0)\n","\n","    def forward(self, x):\n","        # Input shape: [B, C, H, W]\n","        B = x.shape[0]\n","\n","        # Normalize input\n","        x = x.permute(0, 2, 3, 1)  # [B, H, W, C]\n","        x = self.input_norm(x)\n","        x = x.permute(0, 3, 1, 2)  # [B, C, H, W]\n","\n","        # Patch embedding\n","        x = self.patch_embed(x)\n","        x = x.flatten(2).transpose(1, 2)  # [B, N, D]\n","\n","        # Add classification token and position embeddings\n","        cls_tokens = self.cls_token.expand(B, -1, -1)\n","        x = torch.cat((cls_tokens, x), dim=1)\n","        x = x + self.pos_embed\n","\n","        # Transform\n","        x = self.transformer(x)\n","\n","        # Classification from [CLS] token\n","        x = x[:, 0]\n","        x = self.head(x)\n","\n","        return x"],"metadata":{"id":"ztJ_7a8ajwpg","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":12,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def sample_weights(dataset):\n","\n","    labels = []\n","    subset_indices = dataset.indices if hasattr(dataset, 'indices') else range(len(dataset.dataset))\n","\n","    for idx in subset_indices:\n","        if hasattr(dataset, 'dataset'):\n","            _, label = dataset.dataset[idx]\n","        else:\n","            _, label = dataset[idx]\n","        labels.append(label)\n","\n","    labels = np.array(labels)\n","\n","    # Calculate distribution\n","    unique_labels, counts = np.unique(labels, return_counts=True)\n","    print(\"Class distribution:\")\n","    for label, count in zip(unique_labels, counts):\n","        print(f\"Class {label}: {count} samples\")\n","\n","    # Calculate weights\n","    total_samples = len(labels)\n","    class_weights = total_samples / (len(unique_labels) * counts)\n","\n","    # Create sample weights\n","    sample_weights = [class_weights[label] for label in labels]\n","    print(\"Sample weights calculated successfully\")\n","    return torch.FloatTensor(sample_weights)"],"metadata":{"id":"A_IHnVWccPFg","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":12,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, checkpoint_dir, gradient_clip_val=1.0, grad_accum_steps=2):\n","    best_val_acc = 0\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],\n","               'train_f1': [], 'val_f1': []}\n","\n","    patience = 10\n","    early_stop_counter = 0\n","    best_val_f1 = 0\n","\n","    for epoch in range(num_epochs):\n","        logging.info(f'\\nEpoch {epoch+1}/{num_epochs}')\n","        logging.info('-' * 30)\n","\n","        # Training phase\n","        model.train()\n","        train_loss = 0\n","        train_correct = 0\n","        train_total = 0\n","        train_preds = []\n","        train_targets = []\n","        optimizer.zero_grad()  # Zero gradients at the start of epoch\n","\n","        train_pbar = tqdm(train_loader, desc=f'Training Epoch {epoch+1}')\n","\n","        for batch_idx, (inputs, targets) in enumerate(train_pbar):\n","            try:\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, targets)\n","\n","                # Normalize loss for gradient accumulation\n","                loss = loss / grad_accum_steps\n","                loss.backward()\n","\n","                # Gradient accumulation\n","                if (batch_idx + 1) % grad_accum_steps == 0 or batch_idx == len(train_loader) - 1:\n","                    # Clip gradients\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=gradient_clip_val)\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","\n","                    if scheduler is not None:\n","                        scheduler.step()\n","\n","                train_loss += loss.item() * grad_accum_steps\n","                _, predicted = outputs.max(1)\n","                train_total += targets.size(0)\n","                train_correct += predicted.eq(targets).sum().item()\n","                train_preds.extend(predicted.cpu().numpy())\n","                train_targets.extend(targets.cpu().numpy())\n","\n","                current_acc = 100. * train_correct / train_total\n","                train_pbar.set_postfix({\n","                    'loss': f'{loss.item() * grad_accum_steps:.4f}',\n","                    'acc': f'{current_acc:.2f}%'\n","                })\n","\n","            except RuntimeError as e:\n","                if \"out of memory\" in str(e):\n","                    logging.error(\"GPU OOM encountered, clearing cache and skipping batch\")\n","                    if torch.cuda.is_available():\n","                        torch.cuda.empty_cache()\n","                    continue\n","                else:\n","                    raise e\n","\n","        train_loss = train_loss / len(train_loader)\n","        train_acc = 100. * train_correct / train_total\n","        train_f1 = f1_score(train_targets, train_preds, average='weighted')\n","\n","        # Validation phase\n","        model.eval()\n","        val_loss = 0\n","        val_correct = 0\n","        val_total = 0\n","        val_preds = []\n","        val_targets = []\n","\n","        with torch.no_grad():\n","            val_pbar = tqdm(val_loader, desc='Validation')\n","            for inputs, targets in val_pbar:\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, targets)\n","\n","                val_loss += loss.item()\n","                _, predicted = outputs.max(1)\n","                val_total += targets.size(0)\n","                val_correct += predicted.eq(targets).sum().item()\n","                val_preds.extend(predicted.cpu().numpy())\n","                val_targets.extend(targets.cpu().numpy())\n","\n","                current_acc = 100. * val_correct / val_total\n","                val_pbar.set_postfix({\n","                    'loss': f'{loss.item():.4f}',\n","                    'acc': f'{current_acc:.2f}%'\n","                })\n","\n","        val_loss = val_loss / len(val_loader)\n","        val_acc = 100. * val_correct / val_total\n","        val_f1 = f1_score(val_targets, val_preds, average='weighted')\n","\n","        history['train_loss'].append(train_loss)\n","        history['train_acc'].append(train_acc)\n","        history['train_f1'].append(train_f1)\n","        history['val_loss'].append(val_loss)\n","        history['val_acc'].append(val_acc)\n","        history['val_f1'].append(val_f1)\n","\n","        logging.info(f'\\nEpoch Summary:')\n","        logging.info(f'Training Loss: {train_loss:.4f} | Training Acc: {train_acc:.2f}% | Training F1: {train_f1:.4f}')\n","        logging.info(f'Validation Loss: {val_loss:.4f} | Validation Acc: {val_acc:.2f}% | Validation F1: {val_f1:.4f}')\n","\n","        # Save best model based on F1 score\n","        if val_f1 > best_val_f1:\n","            best_val_f1 = val_f1\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'best_val_f1': best_val_f1,\n","                'best_val_acc': val_acc,\n","            }, os.path.join(checkpoint_dir, 'best_model.pth'))\n","            early_stop_counter = 0\n","            logging.info(f'Saved new best model with validation F1: {val_f1:.4f} | Acc: {val_acc:.2f}%')\n","        else:\n","            early_stop_counter += 1\n","\n","        if early_stop_counter >= patience:\n","            logging.info(\"Early stopping triggered\")\n","            break\n","\n","        if torch.cuda.is_available():\n","            torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    return model, history\n"],"metadata":{"id":"LEBtuEj0kGst","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":11,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def plot_training_history(history):\n","    plt.figure(figsize=(12, 4))\n","\n","    # Loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history['train_loss'], label='Training Loss')\n","    plt.plot(history['val_loss'], label='Validation Loss')\n","    plt.title('Model Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    # Accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history['train_acc'], label='Training Accuracy')\n","    plt.plot(history['val_acc'], label='Validation Accuracy')\n","    plt.title('Model Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy (%)')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(PROJECT_PATH, 'training_history.png'))\n","    plt.close()\n"],"metadata":{"id":"UyomC2mokGuz","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":11,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, test_loader, device):\n","    model.eval()\n","    all_preds = []\n","    all_targets = []\n","\n","    with torch.no_grad():\n","        for inputs, targets in test_loader:\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            _, predicted = outputs.max(1)\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_targets.extend(targets.numpy())\n","\n","    return all_preds, all_targets\n"],"metadata":{"id":"O1Z2-cbNkGxb","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":11,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def plot_confusion_matrix(predictions, targets, class_names):\n","    cm = confusion_matrix(targets, predictions)\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\n","    plt.title('Confusion Matrix')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(PROJECT_PATH, 'confusion_matrix.png'))\n","    plt.close()\n","    return cm"],"metadata":{"id":"afUC33I-TdmD","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":10,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["\n","def visualize_wsi_predictions(predictions, coordinates, save_path):\n","    \"\"\"\n","    \"\"\"\n","\n","    colors = {\n","        0: [255, 0, 0],    # Red for Amplified\n","        1: [0, 255, 0],    # Green for Normal\n","        2: [0, 0, 255]     # Blue for Non-Amplified\n","    }\n","\n","    height = max(y for _, y in coordinates) + 512\n","    width = max(x for x, _ in coordinates) + 512\n","    visualization = np.zeros((height, width, 3), dtype=np.uint8)\n","\n","    for pred, (x, y) in zip(predictions, coordinates):\n","        color = colors[pred]\n","        visualization[y:y+512, x:x+512] = color\n","\n","\n","    Image.fromarray(visualization).save(save_path)"],"metadata":{"id":"3v1ALPkwxhwh","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":10,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class GeometricFeatureTransform:\n","    def __init__(self):\n","        self.normalize = transforms.Normalize(\n","            mean=[0.485, 0.456, 0.406, 0.449, 0.449],\n","            std=[0.229, 0.224, 0.225, 0.226, 0.226]\n","        )\n","\n","    def __call__(self, x):\n","        return self.normalize(x)"],"metadata":{"id":"gGthROYixuzT","executionInfo":{"status":"ok","timestamp":1736743098232,"user_tz":-480,"elapsed":10,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["\n","def main():\n","    try:\n","        if not os.path.exists(GEOJSON_DIR):\n","            raise ValueError(f\"GeoJSON directory not found: {GEOJSON_DIR}\")\n","\n","        torch.manual_seed(42)\n","        np.random.seed(42)\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        print(f\"Using device: {device}\")\n","\n","\n","        config = setup_training_config()\n","        batch_size = config['batch_size']\n","\n","\n","        train_transform = GeometricFeatureTransform()\n","        val_transform = GeometricFeatureTransform()\n","\n","\n","        dataset = CancerDataset(GEOJSON_DIR, transform=train_transform)\n","        total_size = len(dataset)\n","\n","        # Stratified split\n","        labels = [annotation['class'] for annotation in dataset.annotations]\n","        train_idx, temp_idx = train_test_split(\n","            range(total_size),\n","            test_size=0.2,\n","            stratify=labels,\n","            random_state=42\n","        )\n","        val_idx, test_idx = train_test_split(\n","            temp_idx,\n","            test_size=0.5,\n","            stratify=[labels[i] for i in temp_idx],\n","            random_state=42\n","        )\n","\n","        # Dataset subsets\n","        train_dataset = torch.utils.data.Subset(dataset, train_idx)\n","        val_dataset = torch.utils.data.Subset(dataset, val_idx)\n","        test_dataset = torch.utils.data.Subset(dataset, test_idx)\n","\n","        print(f\"Train size: {len(train_dataset)}\")\n","        print(f\"Val size: {len(val_dataset)}\")\n","        print(f\"Test size: {len(test_dataset)}\")\n","\n","        # Class weights\n","        class_counts = np.zeros(len(dataset.class_mapping))\n","        for idx in train_idx:\n","            _, label = dataset[idx]\n","            class_counts[label] += 1\n","\n","        # Inverse frequency weighting with smoothing\n","        beta = 0.9999\n","        effective_num = 1.0 - np.power(beta, class_counts)\n","        weights_per_class = (1.0 - beta) / np.where(effective_num < 1e-8, 1e-8, effective_num)\n","        weights_per_class = weights_per_class / np.sum(weights_per_class) * len(weights_per_class)\n","\n","        # Sampler\n","        sample_weights = [weights_per_class[labels[idx]] for idx in train_idx]\n","        sampler = WeightedRandomSampler(\n","            weights=sample_weights,\n","            num_samples=len(train_idx),\n","            replacement=True\n","        )\n","\n","        # Data loaders\n","        train_loader = DataLoader(\n","            train_dataset,\n","            batch_size=batch_size,\n","            sampler=sampler,\n","            num_workers=2,  # Reduced from 4 to 2\n","            pin_memory=True if torch.cuda.is_available() else False\n","        )\n","\n","        val_loader = DataLoader(\n","            val_dataset,\n","            batch_size=batch_size,\n","            shuffle=False,\n","            num_workers=2,\n","            pin_memory=True if torch.cuda.is_available() else False\n","        )\n","\n","        test_loader = DataLoader(\n","            test_dataset,\n","            batch_size=batch_size,\n","            shuffle=False,\n","            num_workers=2,\n","            pin_memory=True if torch.cuda.is_available() else False\n","        )\n","\n","        # Initialize model\n","        print(\"Initializing model...\")\n","        model = ImprovedVisionTransformer(\n","            num_classes=len(dataset.class_mapping),\n","            patch_size=config['patch_size'],\n","            hidden_dim=config['hidden_dim'],\n","            num_heads=config['num_heads'],\n","            num_layers=config['num_layers']\n","        )\n","\n","        model = model.to(device)\n","\n","        # Loss & Optimizer\n","        criterion = create_criterion(weights_per_class, config)\n","        optimizer = create_optimizer(model, config)\n","\n","\n","\n","\n","\n","\n","\n","        num_warmup_steps = len(train_loader) * 5\n","        num_training_steps = len(train_loader) * NUM_EPOCHS\n","\n","        from transformers import get_cosine_schedule_with_warmup\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_training_steps\n","        )\n","\n","\n","\n","\n","\n","\n","        checkpoint_dir = os.path.join(PROJECT_PATH, 'checkpoints')\n","        os.makedirs(checkpoint_dir, exist_ok=True)\n","\n","        # Train model\n","        model, history = train_model(\n","            model=model,\n","            train_loader=train_loader,\n","            val_loader=val_loader,\n","            criterion=criterion,\n","            optimizer=optimizer,\n","            scheduler=scheduler,\n","            num_epochs=NUM_EPOCHS,\n","            device=device,\n","            checkpoint_dir=checkpoint_dir,\n","            gradient_clip_val=gradient_clip_val,\n","            grad_accum_steps=grad_accum_steps\n","        )\n","\n","\n","        plot_training_history(history)\n","\n","        # Load best model\n","        print(\"Loading best model...\")\n","        best_model_path = os.path.join(PROJECT_PATH, 'best_model.pth')\n","        if os.path.exists(best_model_path):\n","            try:\n","                state_dict = torch.load(best_model_path)\n","                if 'model_state_dict' in state_dict:\n","                    model.load_state_dict(state_dict['model_state_dict'])\n","                else:\n","                    model.load_state_dict(state_dict)\n","                print(\"Successfully loaded best model\")\n","            except Exception as e:\n","                print(f\"Could not load model: {str(e)}\")\n","                print(\"Continuing with current model state\")\n","\n","        # Evaluate model\n","        print(\"Evaluating model...\")\n","        predictions, targets = evaluate_model(model, test_loader, device)\n","\n","        # Generate confusion matrix\n","        print(\"Generating confusion matrix...\")\n","        class_names = list(dataset.class_mapping.keys())\n","        cm = plot_confusion_matrix(predictions, targets, class_names)\n","\n","        # Generate classification report\n","        print(\"Classification report...\")\n","        report = classification_report(\n","            targets,\n","            predictions,\n","            target_names=class_names,\n","            digits=4\n","        )\n","        print(\"\\nClassification Report:\")\n","        print(report)\n","\n","\n","\n","\n","\n","\n","        report_path = os.path.join(PROJECT_PATH, 'classification_report.txt')\n","        with open(report_path, 'w') as f:\n","            f.write(report)\n","\n","        final_results = {\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'history': history,\n","            'class_mapping': dataset.class_mapping,\n","            'final_test_predictions': predictions,\n","            'final_test_targets': targets,\n","            'class_weights': weights_per_class.tolist(),\n","            'confusion_matrix': cm.tolist()\n","        }\n","\n","        torch.save(final_results, os.path.join(PROJECT_PATH, 'final_model_results.pth'))\n","\n","    except Exception as e:\n","        print(f\"\\nAn error occurred: {str(e)}\")\n","        import traceback\n","        traceback.print_exc()\n","        raise\n","\n","    finally:\n","        if torch.cuda.is_available():\n","            torch.cuda.empty_cache()\n","\n","if __name__ == '__main__':\n","    main()"],"metadata":{"id":"y0aRbWTnkG1Z","colab":{"base_uri":"https://localhost:8080/","height":527},"outputId":"95b59cfd-35f0-40f5-ed2a-562b0106b2fb","executionInfo":{"status":"error","timestamp":1736743112787,"user_tz":-480,"elapsed":14565,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["Loading annotations: 100%|██████████| 100/100 [00:14<00:00,  6.68it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","An error occurred: 'CancerDataset' object has no attribute '_calculate_class_weights'\n"]},{"output_type":"stream","name":"stderr","text":["\n","Traceback (most recent call last):\n","  File \"<ipython-input-28-793b9e574260>\", line 20, in main\n","    dataset = CancerDataset(GEOJSON_DIR, transform=train_transform)\n","  File \"<ipython-input-16-050b439081ab>\", line 90, in __init__\n","    self.class_weights = self._calculate_class_weights()\n","AttributeError: 'CancerDataset' object has no attribute '_calculate_class_weights'\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'CancerDataset' object has no attribute '_calculate_class_weights'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-793b9e574260>\u001b[0m in \u001b[0;36m<cell line: 217>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-28-793b9e574260>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCancerDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGEOJSON_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtotal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-050b439081ab>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, geojson_dir, transform, phase)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# Calculate class weights for balanced sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_class_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'CancerDataset' object has no attribute '_calculate_class_weights'"]}]}]}